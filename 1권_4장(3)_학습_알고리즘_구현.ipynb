{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1권 4장(3) 학습 알고리즘 구현.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPNR5a4qBzy41659KR8wk/w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tirals88/Deep-Learning-from-Scratch/blob/main/1%EA%B6%8C_4%EC%9E%A5(3)_%ED%95%99%EC%8A%B5_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98_%EA%B5%AC%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mYzE6Fdgaqmy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#드라이브연동\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHXiB0epa7XU",
        "outputId": "66dbf893-8a5f-4e77-b5ed-d7fd92e5a7aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/My Drive/DLscratch/deep-learning-from-scratch/ch04'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1AOQCYt29R2",
        "outputId": "e2ea91da-38d3-4774-f146-78b054642a0e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/DLscratch/deep-learning-from-scratch/ch04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 알고리즘 구현하기\n",
        "\n",
        "---\n",
        "\n",
        "- 전체적인 절차 !\n",
        "\n",
        "신경망에는 적응 가능한 가중치와 편향이 있고, 이 가중치와 편향을 훈련 데이터에 적응하도록 조정하는 과정을 '학습 ( training )'이라고 한다. 다음과 같은 4단계로 수행한다.\n",
        "\n",
        "- 1단계 - 미니배치\n",
        "\n",
        "훈련 데이터 중 일부를 무작위로 가져온다. 이렇게 선별한 데이터를 미니배치라 하며, 그 미니배치의 손실 함수 값을 줄이는 것이 목표이다."
      ],
      "metadata": {
        "id": "1w0uheJYC4Sj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 미니배치\n",
        "\n",
        "batch_mask = np.random.choice(60000, 10)\n",
        "print(batch_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNEsg_c0Jg8N",
        "outputId": "28102b4d-4532-42f1-be82-9ee2294434fd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[34452 34746 55031 22305 24912 42353 29094 10205  3785  1394]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.argamx() 이해\n",
        "\n",
        "x = np.array([[.1, .7, .2], [.3, .1, .6],[.2, .5, .3],[.8, .1, .1]])\n",
        "y= np.argmax(x)\n",
        "print(y) # x.reshape(1, x.size) 한 이후 나온 index 와 같음\n",
        "\n",
        "x2 = np.array([[1, 2, 3], [9, 8, 7], [10, 12, 11], [5, 6, 7]])\n",
        "y2 = np.argmax(x2,axis = 0)\n",
        "y3 = np.argmax(x2,axis = 1)\n",
        "\n",
        "print(y2, y3)\n",
        "\n",
        "# axis = 0 , 1 -> y, x 축 순 ( 0차원 , 1차원 순 임)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtMomQAOC2r5",
        "outputId": "325fa49d-c917-4477-a95c-800f97dbf2ba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "[2 2 2] [2 0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 2단계 - 기울기 산출\n",
        "\n",
        "미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구한다. 기울기는 손실 함수의 값을 가장 작게하는 방향을 제시한다.\n",
        "\n",
        "- 3단계 - 매개변수 갱신\n",
        "\n",
        "가중치 매개변수를 기울기 방향으로 아주 조금 갱신한다.\n",
        "\n",
        "- 4단계  - 반복\n",
        "\n",
        "1~3단계를 반복한다."
      ],
      "metadata": {
        "id": "F0PdwPeCJI6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 과정은 경사 하강법으로 매개변수를 갱신하는 방법이며, 이 때 데이터를 미니배치로 무작위로 선정하기 때문에 확률적 경사 하강법이라고 부른다. - SGD"
      ],
      "metadata": {
        "id": "kuctgAo_QQpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 손글씨 숫자 학습 신경망 구현\n",
        "# 2층 신경망을 하나의 클래스로 구현한다. ( TwoLayerNet / ch04/two_layer_net.py )\n",
        "\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "from common.functions import *\n",
        "from common.gradient import numerical_gradient\n",
        "\n",
        "class TwoLayerNet:\n",
        "  def __init__(self, input_size, hidden_size, output_size,\n",
        "               weight_init_std = 0.01):\n",
        "    \n",
        "    # 가중치 초기화\n",
        "    self.params = {}\n",
        "    self.params['W1'] = weight_init_std * \\\n",
        "                        np.random.randn(input_size, hidden_size)\n",
        "    self.params['b1'] = np.zeros(hidden_size)\n",
        "    self.params['W2'] = weight_init_std * \\\n",
        "                        np.random.randn(input_size, hidden_size)\n",
        "    self.params['b2'] = np.zeros(hidden_size)\n",
        "\n",
        "  def predict(self, x):\n",
        "    W1, W2 = self.params['W1'], self.params['W2']\n",
        "    b1, b2 = self.params['b1'], self.params['b2']\n",
        "\n",
        "    a1 = np.dot(x, W1) + b1\n",
        "    z1 = sigmoid(a1)\n",
        "    a2 = np.dot(z1, W2) + b2\n",
        "    z2 = sigmoid(a2)\n",
        "\n",
        "    return y2\n",
        "\n",
        "  # x : 입력 데이터, t : 정답 레이블\n",
        "  def loss(self, x, t):\n",
        "    y = self.predict(x)\n",
        "\n",
        "    return cross_entropy_error(y, t)\n",
        "\n",
        "  def accuracy(self, x, t):\n",
        "    y = self.predict(x)\n",
        "    y = np.argmax(y, axis = 1)\n",
        "    t = np.argmax(t, axis = 1)\n",
        "\n",
        "    accuracy = np.sum(y == t) / float(x.shpae[0])\n",
        "    return accuracy\n",
        "\n",
        "  # x : 입력 데이터, t : 정답 레이블 \n",
        "  def numerical_gradient(self, x, t):\n",
        "    loss_W = lambda W : self.loss(x, t)\n",
        "\n",
        "    grads = {}\n",
        "    grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "    grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "    grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "    grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "\n",
        "    return grads"
      ],
      "metadata": {
        "id": "ywEGaZhsG-dF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = TwoLayerNet(input_size = 784, hidden_size = 100, output_size = 10)\n",
        "print(net.params['W1'].shape)\n",
        "print(net.params['b1'].shape)\n",
        "print(net.params['W2'].shape)\n",
        "print(net.params['b2'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk35qY5DQ_Ci",
        "outputId": "b0228098-aa4a-48c0-e3f9-e0bd54ef6813"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 100)\n",
            "(100,)\n",
            "(784, 100)\n",
            "(100,)\n"
          ]
        }
      ]
    }
  ]
}