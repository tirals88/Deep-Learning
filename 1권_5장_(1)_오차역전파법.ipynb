{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1권 5장 (1) 오차역전파법.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP48vfzY7GiQlCC8zRXe1ZL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tirals88/Deep-Learning-from-Scratch/blob/main/1%EA%B6%8C_5%EC%9E%A5_(1)_%EC%98%A4%EC%B0%A8%EC%97%AD%EC%A0%84%ED%8C%8C%EB%B2%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#드라이브연동\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "WHXiB0epa7XU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58302836-14d2-4c9c-fd42-2f5cea2f0e9b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/My Drive/DLscratch/deep-learning-from-scratch/ch05'"
      ],
      "metadata": {
        "id": "i1AOQCYt29R2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d35195b-59d6-4664-c184-a25435a4222f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/DLscratch/deep-learning-from-scratch/ch05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "from common.functions import *"
      ],
      "metadata": {
        "id": "fMbUSRq0pwSF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "8PfuZ2hXa4zk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 오차역전파법\n",
        "\n",
        "앞 장에서는 신경망 학습에 대해서 설명을 하였다. 그 때는 가중치 매개변수의 손실함수의 기울기를 수치 미분을 사용하여 구하였다.\n",
        "수치미분은 구현이 쉽고 단순하지만 오래걸린다는 단점이 있었다. 이번에는 효율적으로 계산하는 '오차역전파법'을 배워볼 것이다.\n",
        "\n",
        "먼저 시작적 ( 계산 그래프를 통하여 )으로 이해를 해보자.\n",
        "\n",
        "오차역전파법을 계산 그래프로 설명한다는 생각은 **Andrej Karpathy**의 블로그, **Fei-Fei Li** 교수가 진행한 스탠퍼드 대학교의 딥러닝 수업 CS231n을 참고하였다고한다.\n",
        "물론 내가 정리한 모든 내용들 또한 **밑바닥부터 시작하는 딥러닝(Deep Learning from Scratch)**의 내용들이다."
      ],
      "metadata": {
        "id": "GcyC0jIxw5Yc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 계산그래프\n",
        "\n",
        "그림을 통한 이해는 책을 통해 복습\n",
        "https://github.com/WegraLee/deep-learning-from-scratch/tree/master/ch05\n",
        "\n"
      ],
      "metadata": {
        "id": "rDdHMefly3FH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "계산 그래프의 특징은 '국소적 계산'을 전파함으로써 최종 결과를 얻는다는 점에 있다.\n",
        "\n",
        "국소적 계산은 결국 전체에서 어떤 일이 벌어지든 상관없이 독립적으로 자신과 관계된 정보만으로 결과를 출력할 수 있다는 것이다.\n",
        "\n",
        "👉 각 노드는 자신과 관련된 계산 외에는 아무것도 신경 쓸 게 없다.\n",
        "\n",
        "국소적 계산의 장점\n",
        "1. 전체가 아무리 복잡하더라도 각 노드에서는 단순한 계산에 집중하여 문제를 단순화 할 수 있다.\n",
        "2. 중간 계산 결과를 모두 보관할 수 있다.\n",
        "3. **역전파를 통해 '미분'을 효율적으로 계산할 수 있다.**\n",
        "\n"
      ],
      "metadata": {
        "id": "2JopivrK2vRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 연쇄법칙\n",
        "\n",
        "합성함수\n",
        "- 여러 함수로 굿어된 함수이다.\n",
        "$z = (x + y)^2$, 이 식은 아래의 두 개의 식으로 구성된 것이다.\n",
        "$$z = t^2$$\n",
        "$$t = x + y$$\n",
        "\n",
        "- 합성 함수의 미분은 합성 함수를 구성하는 각 함수의 미분의 곱으로 나타내진다.\n",
        "$$\\frac{\\partial z}{\\partial x} = \\frac{∂z}{∂t}\\frac{∂t}{∂x}$$\n",
        "\n",
        "위 식에서 $∂t$는 서로 지울 수 있다.\n",
        "\n",
        "$$\\frac{∂z}{∂t} = 2t$$\n",
        "\n",
        "$$\\frac{∂t}{∂x} = 1$$\n",
        "\n",
        "$$\\frac{\\partial z}{\\partial x} = \\frac{∂z}{∂t}\\frac{∂t}{∂x} = 2t ⋅1 = 2(x+y)$$\n",
        "\n",
        "- 국소적 미분의 전달\n",
        "\n",
        "$→ \\frac{\\partial z}{\\partial z}$ \n",
        "\n",
        "$→ \\frac{∂z}{∂z}\\frac{∂z}{∂t}$ \n",
        "\n",
        "$→ \\frac{\\partial z}{\\partial z}\\frac{∂z}{∂t}\\frac{∂t}{∂x}$\n",
        "\n",
        "이는 결국 $x$에 대한 $z$의 미분이 된다."
      ],
      "metadata": {
        "id": "IbniO36NCeYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 덧셈 노드의 역전파\n",
        "\n",
        "$z = x + y$에서 $\\frac{∂z}{∂x} = 1$, $\\frac{∂z}{∂y} = 1$이 된다.\n",
        "\n",
        "그러므로 덧셈 노드에서 역전파는 상류에서 전해진 미분 ( $\\frac{∂L}{∂z}$에 1을 곱하여 하류로 흘려보내는 것이다. 즉 1을 곱하기만 할 분이므로 입력된 값을 그대로 다음 노드로 흘려보내게 된다.\n",
        "\n",
        "덧셈 노드 역전파는 입력 신호를 다음 노드로 출력할 뿐이므로 그대로 다음 노드로 전달한다."
      ],
      "metadata": {
        "id": "eK4SC1RHETeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 곱셈 노드의 역전파\n",
        "\n",
        "$z = x ⋅ y$에서 $\\frac{∂z}{∂x} = y$, $\\frac{∂z}{∂y} = x$가 된다.\n",
        "\n",
        "곱셈 노드 역전파는 상류의 값에 순전파 때의 입력 신호들을 '서로 바꾼 값'을 곱해서 하류로 보낸다.\n",
        "\n",
        "**덧셈의 역전파는 상류의 값을 그대로 흘려보내기 대문에 순방향 입력 신호의 값은 필요하지 않았지만,**\n",
        "\n",
        "**곱셈의 역전파는 순방향 입력 신호의 값이 필요하다. 그래서 곱셈 노드를 구현할 때는 순전파의 입력 신호를 변수에 저장해둔다.**"
      ],
      "metadata": {
        "id": "bTz8KdCGH39u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 단순 계층 구현\n",
        "\n",
        "- 곱셈 노드 : MulLayer\n",
        "\n",
        "- 덧셈 노드 : AddLayer\n",
        "\n",
        "- 계층 : 신경망의 기능 단위. / 예를 들어 시그모이드 함수를 위한 Sigmoid, 행렬 곱을 위한 Affine 등이 해당 됨"
      ],
      "metadata": {
        "id": "y711AgHa5t3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 곱셈 계층\n",
        "\n",
        "모든 계층은 forward() / backward() 공통의 메서드(인터페이스)를 갖도록 구현할 것이다."
      ],
      "metadata": {
        "id": "z7v1qh5Q6H4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 곱셈 계층 \n",
        "\n",
        "class MulLayer():\n",
        "  def __init__(self):\n",
        "    self.x = None\n",
        "    self.y = None\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    out = x * y\n",
        "\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dx = dout * self.y # x 와 y 를 바꿔 곱한다\n",
        "    dy = dout * self.x\n",
        "\n",
        "    return dx, dy"
      ],
      "metadata": {
        "id": "K910qxDv2NrY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apple = 100\n",
        "apple_num = 2\n",
        "tax = 1.1\n",
        "\n",
        "# 계층들\n",
        "\n",
        "mul_apple_layer = MulLayer()\n",
        "mul_tax_layer = MulLayer()\n",
        "\n",
        "# 순전파\n",
        "\n",
        "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
        "price = mul_tax_layer.forward(apple_price, tax)\n",
        "\n",
        "print(price) # 220"
      ],
      "metadata": {
        "id": "9-mDKDPn66LU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b68e202c-5fed-45ba-d8c4-91ef91c6266e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220.00000000000003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 역전파\n",
        "\n",
        "dprice = 1\n",
        "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
        "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
        "\n",
        "print(dapple, dapple_num, dtax)"
      ],
      "metadata": {
        "id": "tOLxMtwK914i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed61816e-e771-4ec9-b97c-94f6adc4893c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2 110.00000000000001 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 덧셈 계층\n",
        "\n",
        "곱셈과 같이 forward() / backward() 구분"
      ],
      "metadata": {
        "id": "wGDNQiOyBbqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AddLayer():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def forward(self, x, y):\n",
        "    out = x + y\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dx = dout * 1\n",
        "    dy = dout * 1\n",
        "    return dx, dy"
      ],
      "metadata": {
        "id": "Bt902Ht4-48B"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 활성화 함수 계층 구현\n",
        "\n",
        "- Relu\n",
        "\n",
        "- Sigmoid"
      ],
      "metadata": {
        "id": "lto-T7eCEM6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relu 계층\n",
        "\n",
        "활성화 함수로 사용되는 ReLU의 수식은 다음과 같다.\n",
        "\n",
        "$$y = \\begin{cases}x  (x > 0)\\\\0  (x\\leq0)\\end{cases}$$\n",
        "\n",
        "\n",
        "위 식에서 $x$ 에 대한 $y$ 의 미분은 아래와 같다.\n",
        "\n",
        "$$ \\frac{\\partial y}{\\partial x} = \\begin{cases}1 (x > 0)\\\\0 (x\\leq0)\\end{cases}$$\n",
        "\n",
        "위와 같이 순전파 때의 입력인 x가 0보다 크면 역전파는 상류의 값을 그대로 하류로 흘린다.\n",
        "\n",
        "반면, 순전파 때 $x$가 0 이하면 역전파 때는 하류로 신호를 보내지 않는다. ( 0을 보낸다 )"
      ],
      "metadata": {
        "id": "KLfvJMT2EXHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ReLU 계층 구현\n",
        "\n",
        "class ReLU:\n",
        "  def __init__(self):\n",
        "    self.mask = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.mask = ( x <= 0 ) # 0 보다 작은 원소들의 인수들을 True\n",
        "    out = x.copy()\n",
        "    out[self.mask] = 0  # 0 보다 작은 원소들 0으로 치환\n",
        "\n",
        "    return out\n",
        "  \n",
        "  def backward(self, dout):\n",
        "    dout[self.mask] = 0\n",
        "    dx = dout\n",
        "\n",
        "    return dx"
      ],
      "metadata": {
        "id": "ZWio8mSCEWS-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sigmoid 계층\n",
        "\n",
        "시그모이드 함수는 다음과 같다.\n",
        "$$y = \\frac{1}{1+\\exp(-x)}$$\n",
        "\n",
        "시그모이드 계층의 계산 그래프는 다음과 같다.\n",
        "1. $x$ / $-1$ 의 곱셈 계층 : $-x$\n",
        "2. $-x$ 의 exp 계층 : exp($-x$)\n",
        "3. exp($-x$)와 1의 더하기 계층 : 1 + exp($-x$)\n",
        "4. 1 + exp($-x$)의 나누기 계층 : $\\frac{1}{1+\\exp(-x)}$"
      ],
      "metadata": {
        "id": "BTK1AQV1T_Rm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1단계 '/' 노드, $y = \\frac{1}{x}$ 을 미분하면 다음 식이 된다.\n",
        "\n",
        "$$\\frac{\\partial y}{\\partial x} = -\\frac{1}{x^2} = -y^2$$\n",
        "\n",
        "위 식에 따라 역전파 때는 상류에서 흘러온 값에 $-y^2$ (순전파의 출력을 제곱한 후 마이너스를 붙인 값)을 곱해서 하류로 전달한다.\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial y} → -\\frac{\\partial L}{\\partial y}y^2$$\n",
        "\n",
        "- 2단계 '+' 노드, 상류의 값을 그대로 하류로 흘려보낸다. \n",
        "\n",
        "- 3단계 '$\\exp$'노드, $y = \\exp(x)$ 연산을 수행하며, 그 미분은 다음과 같다.\n",
        "\n",
        "$$\\frac{\\partial y}{\\partial x} = \\exp(x)$$\n",
        "\n",
        "위 식에 따라 역전파 때는 상류에서 흘러온 값에 순전파의 출력 ($\\exp(-x)$)을 곱하여 하류로 흘려보낸다.\n",
        "\n",
        "$$-\\frac{\\partial L}{\\partial y}y^2 →-\\frac{\\partial L}{\\partial y}y^2\\exp(-x) $$\n",
        "\n",
        "- 4단계 'x' 노드, 순전파 때의 값을 '서로 바꿔' 곱하여 내보낸다.\n",
        "\n",
        "이 예에서는 '-1'을 곱한다.\n",
        "\n",
        "결국 최종 출력 값으로 $\\frac{\\partial L}{\\partial y}y^2\\exp(-x)$이 된다."
      ],
      "metadata": {
        "id": "RBR7PZFKO3sI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Sigmoid 계층의 계산 그래프 ( 간소화 버전 )\n",
        "\n",
        "<img src = \"https://github.com/tirals88/Deep-Learning-from-Scratch/blob/main/deep_learning_images/fig%205-21.png?raw=true\">\n",
        "\n",
        "<출처 : \" https://github.com/WegraLee/deep-learning-from-scratch.git \">\n",
        "\n",
        "위와 같이 간소화 버전은 중간 계산들을 생략할 수 있어서 더 효율적인 계산이라 할 수 있다.\n",
        "\n",
        "또한 $\\frac{\\partial L}{\\partial y}y^2\\exp(-x)$는 다음처럼 정리해서 쓸 수도 있다.\n",
        "\n",
        "<img src = \"https://github.com/tirals88/Deep-Learning-from-Scratch/blob/main/deep_learning_images/e%205.12.png?raw=true\">\n",
        "\n",
        "위와 같이 Sigmoid 계층의 역전파는 순전파의 출력 ($y$)만으로 계산이 가능하다."
      ],
      "metadata": {
        "id": "CXuYKIwWXKMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sigmoid 계층 구현\n",
        "\n",
        "class Sigmoid:\n",
        "  def __init__(self):\n",
        "    self.out = None\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = 1 / (1 + np.exp(-x))\n",
        "    self.out = out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dx = dout * (1.0 - self.out) * self.out\n",
        "\n",
        "    return dx\n",
        "  \n",
        "# 순전파의 출력을 인스턴스 변수 out에 보관했다가, 역전파 계산 때 그 값을 사용한다."
      ],
      "metadata": {
        "id": "w2FXe0QHY7Da"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Affine / Softmax 계층 구현\n",
        "\n",
        "## Affine 계층\n",
        "\n",
        "신경망의 순전파에서는 가중치 신호의 총합을 계산하기 때문에 행렬의 곱을 사용하였다.\n",
        "\n",
        "```\n",
        "X = np.random.rand(2)    # 입력\n",
        "W = np.random.rand(2, 3) # 가중치\n",
        "B = np.random.rand(3)    # 편향\n",
        "\n",
        "Y = np.dot(X, W) + B\n",
        "```\n",
        "신경망의 순전파 때 수행하는 행렬의 곱은 기하학에서는 **어파인 변환 affine transformation**이라고 한다.\n"
      ],
      "metadata": {
        "id": "dW1A2sGbeGf4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전까지의 계산 그래프는 노드 사이에 '스칼라 값'이 흘렀는 데 반해, 이 예에서는 '행렬'이 흐르고 있다.\n",
        "\n",
        "행렬을 사용한 역전파도 행렬의 원소마다 전개해보면 스칼라값을 사용한 지금까지의 계산 그래프와 같은 순서로 생각할 수 있다.\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial X} = \\frac{\\partial L}{\\partial Y} ⋅ W^T$$\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial W} = X^T\\cdot\\frac{\\partial L}{\\partial Y}$$\n",
        "\n",
        "\n",
        "$\\frac{\\partial L}{\\partial X}$ 는 스칼라 값의 MulLayer 에서 $dx$가 되며, $W^T = \\frac{\\partial Y}{\\partial X}$ 이므로 $\\frac{\\partial L}{\\partial X} = \\frac{\\partial L}{\\partial Y} ⋅ W^T = \\frac{\\partial L}{\\partial Y} ⋅ \\frac{\\partial Y}{\\partial X}$ 가 되어 연쇄법칙이 성립한다.\n",
        "\n",
        "<img src = \"https://github.com/tirals88/Deep-Learning-from-Scratch/blob/main/deep_learning_images/fig%205-25.png?raw=true\">\n"
      ],
      "metadata": {
        "id": "3fytls5Th9T4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "$X$와 $\\frac{\\partial L}{\\partial X}$, $W$와 $\\frac{\\partial L}{\\partial W}$은 서로 형상이 같다.\n",
        "\n",
        "$X$ = ($x_0$, $x_1$, ..., $x_n$)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial X}$ = ($\\frac{\\partial L}{\\partial x_0}$, $\\frac{\\partial L}{\\partial x_1}$, ..., $\\frac{\\partial L}{\\partial x_n}$)"
      ],
      "metadata": {
        "id": "f9jXeWEmUaWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  배치용 Affine 계층\n",
        "\n",
        "데이터가 $N$ 개가 묶여서 학습이 진행이 될 때, 각 데이터마다 편향 $b$는 더해진다.\n",
        "\n",
        "그리고 역전파 때는 각 데이터마다 $\\frac{\\partial L}{\\partial B}$ = $\\frac{\\partial L}{\\partial Y}$ 이므로 반대로 편향 $b$에 데이터들의 미분값이 모이게 된다.\n",
        "\n",
        "<img src = \"https://github.com/tirals88/Deep-Learning-from-Scratch/blob/main/deep_learning_images/fig%205-27.png?raw=true\">"
      ],
      "metadata": {
        "id": "LkrfoSuqW-rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Affine:\n",
        "  def __init__(self, W, b):\n",
        "    self.W = W\n",
        "    self.b = b\n",
        "    self.x = None\n",
        "    self.dW = None\n",
        "    self.db = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.x = x\n",
        "    out = np.dot(x, self.W) + self.b\n",
        "\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dx = np.dot(dout, self.W.T)\n",
        "    self.dW = np.dot(self.x.T, dout)\n",
        "\n",
        "    self.db = np.sum(dout, axis = 0)\n",
        "\n",
        "    return dx"
      ],
      "metadata": {
        "id": "1Kn1YsZWTV8a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Softmax-with-Loss 계층\n",
        "\n",
        "출력층에서 사용되는 소프트맥스 함수는 입력 값을 정규화하여 출력한다.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def softmax(a):\n",
        "  c = np.max(a)\n",
        "  exp_a = np.exp(a-c)\n",
        "  sum_exp_a = np.sum(exp_a)\n",
        "  y = exp_a / sum_exp_a\n",
        "\n",
        "  return y\n",
        "```\n",
        "<img src = \"https://github.com/tirals88/Deep-Learning-from-Scratch/blob/main/deep_learning_images/fig%205-28.png?raw=true\">\n",
        "\n",
        "위 그림과 같은 경우는 손글씨 데이터 이므로 가짓수가 10개이며 Softmax 계층의 입력 또한 10개가 된다.\n",
        "\n",
        "신경망에서 수행하는 작업은 **학습**과 **추론**이 있다.\n",
        "\n",
        "추론할 때는 일반적으로 Softmax 계층을 사용하지 않는다. 신경망에서 정규화하지 않은 출력 결과를 ***Score*** 라고 하는데, 추론단계에서는 가장 높은 Score 값만 필요하므로 Softmax 계층이 필요가 없어지기 때문이다.\n",
        "\n",
        "그러나 신경망을 학습하는 과정에서는 Softmax 계층이 필요해진다.\n"
      ],
      "metadata": {
        "id": "nogFR17HZ1ua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Softmax-with-Loss 계층 구현\n",
        "\n",
        "<img src = \"https://github.com/tirals88/Deep-Learning-from-Scratch/blob/main/deep_learning_images/fig%205-29.png?raw=true\">\n",
        "\n"
      ],
      "metadata": {
        "id": "7A14bWeaexbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.arange(0, 1, 0.02)\n",
        "x = np.arange(0, 1, 0.02)\n",
        "logy = np.log(y)\n",
        "\n",
        "plt.plot(x, logy)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oiQpt4kAa8N9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "e0114af7-4412-48d2-d717-61eca6a0d7eb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위와 같이 CEE는 입력 값이 1에 가까울 수록 Error 값이 작아지도록 설계되어있다.\n",
        "여기서 입력 값은 Softmax 출력 값으로 정규화 되어있어 0 ~ 1 사이의 값들이다."
      ],
      "metadata": {
        "id": "-g57YQa_yCQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Softmax-with-Loss 계층의 계산 그래프\n",
        "\n",
        "먼저 Cross Entropy Error 층의 역전파를 계산한다. 이 과정은 비교적 쉽게 계산된다.\n",
        "\n",
        "1. 곱셈 / 덧셈 / 곱셈 계층의 순서대로 계산을 하면 $t_1, t_2, t_3$이 나온다.\n",
        "2. $\\log x$ 대해서 미분 값은 $\\frac{1}{x}$ 이므로 $t_1$에 대하여 $\\log$ 계층의 역전파 값은 $-\\frac{t_1}{y_1}$이 된다.\n",
        "\n",
        "다음으로 Softmax 계층으로 역전파를 이어나가면 보다 복잡해진다.\n",
        "\n",
        "0. ⭕ 먼저 순전파 때, 출력값이 여러 계층에 입력이 된다면 반대로 역전파 때는 이 출력값들의 합에 대하여 미분을 계산하여야 한다. ⭕\n",
        "1. 첫번째 역전파 계층인 곱셈 계층의 역전파 출력값으로 $-\\frac{t_1}{y_1} ⋅ \\exp(a_1) = -{t_1}\\frac{\\exp(a_1)}{\\exp(a_1)}{S} = -{t_1}S$ 과 $-\\frac{t_1}{y_1} ⋅ \\frac{1}{S} = -\\frac{t_1}{\\exp(a_1)}$ 이 나오게된다.\n",
        "2. 먼저 앞의 값인 $-t_1S$ 에 대해서 다음 노드인 '/' 노드를 계산하면 $\\frac{dy}{dS} = -\\frac{1}{S^2}$이 되며, 순전파 때 3개의 갈래로 나뉘어 흘러갔던 값들을 다 더해주면 ($-t_1S -t_2S -t_3S)\\cdot -\\frac{1}{S^2}$ = $\\frac{1}{S}(t_1+t_2+t_3)$이 된다.\n",
        "\n",
        "- 여기서 (t_1, t_2, t_3)는 '원-핫 벡터'이며 이는 이 값들 중 단 하나만 1이고 나머지는 전부 0이다. 따라서 (t_1+t_2+t_3) = 1 이 된다.\n",
        "\n",
        "3. $\\frac{1}{S}(t_1+t_2+t_3) = \\frac{1}{S}$, 다음 노드인 '+'노드는 역전파 시 입출력이 같기 때문에 그대로의 값을 내보낸다.\n",
        "\n",
        "4. 다음으로 '$\\exp$'노드에 대해서 풀게 되면 먼저 구한 $-\\frac{t_1}{\\exp(a_1)}$와 $\\frac{1}{S}$이 입력값으로 들어가게 된다.\n",
        "\n",
        "5. '$\\exp$' 노드의 미분 값은 $\\exp(a_1)$이 되며, 이 노드의 역전파 값은 $(-\\frac{t_1}{\\exp(a_1)} + \\frac{1}{S}) \\cdot \\exp(a_1)$ = $\n",
        "\\frac{\\exp(a_1)}{S}-t_1 = y_1 - t_1$\n",
        "\n",
        "\n",
        "**이 두 계층의 역전파 값으로 $y_1 - t_1$라는 아주 깔끔한 값이 나오게 된다.**\n",
        "\n"
      ],
      "metadata": {
        "id": "2SBG1u5b33rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 계층 구현 코드\n",
        "\n",
        "class SoftmaxWithLoss():\n",
        "  def __init__(self):\n",
        "    self.loss  = None #손실\n",
        "    self.y = None     #softmax 출력\n",
        "    self.t = None     #정답 레이블 (원 핫 벡터)\n",
        "\n",
        "  def forward(self, x, t):\n",
        "    self.t = t\n",
        "    self.y = softmax(x)\n",
        "    self.loss = cross_entropy_error(self.y, self.t)\n",
        "\n",
        "    return self.loss\n",
        "\n",
        "  def backward(self, dout = 1):\n",
        "    batch_size = self.t.shape[0]\n",
        "    dx = (self.y - self.t) / batch_size\n",
        "\n",
        "    return dx"
      ],
      "metadata": {
        "id": "0EQtSibTxiRe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[2, 8, 10, 4], [1, 3, 6, 1]])\n",
        "t = np.array([[0,0,1,0],[0,0,1,0]])\n",
        "\n",
        "A = SoftmaxWithLoss()\n",
        "a = A.forward(x, t)\n",
        "\n",
        "y = np.array([[0.1, 0.2 ,10, 1], [-0.1, 0.5, 20, -0.2]])\n",
        "B = SoftmaxWithLoss()\n",
        "b = B.forward(y, t)\n",
        "print(a)\n",
        "print(A.backward())\n",
        "\n",
        "print(b)\n",
        "print(B.backward())"
      ],
      "metadata": {
        "id": "9-FEoXwHqIw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14fd40d6-7644-4051-d309-634e42a03089"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.095372961192538\n",
            "[[ 0.00014737  0.05945409 -0.0606904   0.00108894]\n",
            " [ 0.00316852  0.0234124  -0.02974944  0.00316852]]\n",
            "0.00011440839436362912\n",
            "[[ 2.50815964e-05  2.77194510e-05 -1.14491820e-04  6.16907726e-05]\n",
            " [ 9.32504454e-10  1.69913390e-09 -3.47540330e-09  8.43764923e-10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A와 B의 역전파 값 비교\n",
        "print('A 오차 합 : ', np.sum(A.backward(), axis=1))\n",
        "print('B 오차 합 : ', np.sum(B.backward(), axis=1))"
      ],
      "metadata": {
        "id": "pd8OB-_NtYnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9343a550-ad22-4a60-bf33-6c2ef7f7872d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A 오차 합 :  [2.64545330e-17 2.94902991e-17]\n",
            "B 오차 합 :  [ 2.04914211e-17 -2.31843991e-17]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(A.backward())"
      ],
      "metadata": {
        "id": "hyw7iBuSvz8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2265680-0660-47ff-85bb-a270200785a3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.00014737  0.05945409 -0.0606904   0.00108894]\n",
            " [ 0.00316852  0.0234124  -0.02974944  0.00316852]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = A.backward()\n",
        "print(d)\n",
        "type(d)"
      ],
      "metadata": {
        "id": "ztyY0dEMwAJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b27f2d3c-aaa7-4f58-d2d7-36de8ecf5add"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.00014737  0.05945409 -0.0606904   0.00108894]\n",
            " [ 0.00316852  0.0234124  -0.02974944  0.00316852]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(d, axis = 1)"
      ],
      "metadata": {
        "id": "VXsLOcv1w2mL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b7eb76-b350-4f25-ac29-061471b26f49"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.64545330e-17, 2.94902991e-17])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}